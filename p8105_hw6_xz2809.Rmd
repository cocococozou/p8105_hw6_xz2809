---
title: "P8105_hw6_xz2809"
author: "Coco Zou (xz2809)"
date: "11/24/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(modelr)
library(mgcv)
set.seed(1)
```

##Problem 1

Here is the **code chunk** to read csv file and conduct the data wrangling. We create a "city_state" variable which combines city and state together. We also create a binary variable indicating whether the homicide is solved. We then omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO – these don’t report victim race. Also omit Tulsa, AL – this is a data entry mistake. We then modifiy "victim_race"" to have categories white and non-white, with white as the reference category. 

```{r  message=FALSE, warning=FALSE}
homicide_df <- read_csv(file = "./data/homicide-data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(city_state = paste(city,state,sep=", "),
         resolved = case_when(disposition == "Closed by arrest"~1,
                              TRUE ~ 0),
         victim_age = as.numeric(victim_age)) %>% 
  filter(!(city_state %in% c("Dallas, TX","Phoenix, AZ","Kansas City, MO", "Tulsa, AL"))) %>% 
  mutate(victim_race_modified = case_when(victim_race == "White"~"white",
                                          TRUE~"non_white"),
         victim_race = as.factor(victim_race_modified))%>% 
  select(-victim_race_modified) %>% 
  within(victim_race <- relevel(victim_race, ref = "white"))
  
```

For the city of Baltimore, MD, we use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors. The estimate and confidence interval of the adjusted odds ratio for solving homicides comparing non-white victims to white victims are shown in the table below. 

```{r  message=FALSE, warning=FALSE}
baltimore_df = 
  homicide_df %>% 
  filter(city == "Baltimore")

fit_logistic = 
  baltimore_df %>% 
  glm(resolved ~ victim_age + victim_race + victim_sex, data = ., family = binomial()) 

fit_table = fit_logistic %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate)) %>%
  select(term, log_OR = estimate, OR) %>% 
  filter((term %in% c("victim_racenon_white")))

fit_table %>% 
  knitr::kable(digits = 3)

ci = confint(fit_logistic,level=0.95) %>% 
  as.tibble() 

ci <- ci[3,]

ci %>% 
  knitr::kable(digits = 3)
                         
```

Here is the **code chunk** to run glm for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing non-white victims to white victims.
```{r  message=FALSE, warning=FALSE}
homicide_df_model = homicide_df %>% 
  select(victim_age,victim_sex,victim_race,resolved,city_state) %>% 
  group_by(city_state) %>% 
  nest() %>% 
  mutate(models = map(data, ~glm(resolved ~ victim_age + victim_sex+victim_race, data = .x, family = binomial())),
         ci = map(models,confint),
         ci = map(ci,broom::tidy),
         models = map(models, broom::tidy)) %>% 
  select(-data) %>% 
  unnest() %>% 
  filter((term %in% c("victim_racenon_white"))) %>% 
  mutate(OR = exp(estimate),
         low_bond = exp(X2.5..),
         high_bond = exp(X97.5..)) %>% 
  select(city_state,low_bond,high_bond,OR)
```

Here is the code chunk to create a plot that shows the estimated ORs and CIs for each city. 
```{r  message=FALSE, warning=FALSE}
homicide_df_model %>% 
  ggplot()+
  geom_point(aes(reorder(city_state,OR), y = OR))+
  geom_errorbar(aes(x=city_state, ymin = low_bond, ymax = high_bond))+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(
    title = "Cities vs Estimated ORs with 95% CI",
    x = "Cities",
    y = "Estimated ORs"
  )
```

As we can see from the plot above, Boston has the lowest OR around 0.2 while Tampa has the highest OR around 1.2. The confidence interval slightly increases with the estimate OR increasing. 

##Problem 2

Here is the **code chunk** to read the csv file and conduct the data wrangling

```{r message=FALSE, warning=FALSE}
birthweight_df = read_csv(file = "./data/birthweight.csv") %>% 
  na.omit() %>% 
  mutate(babysex = as.factor(babysex),
         frace = as.factor(frace),
         mrace = as.factor(mrace),
         malform = as.factor(malform))
```

Here is the **code chunk** to propose a regression model for birthweight. 

```{r message=FALSE, warning=FALSE}
cv_df = 
  crossv_mc(birthweight_df, 100) %>% 
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble))

myfit =  lm(bwt ~ ppbmi + wtgain + gaweeks, data = birthweight_df)
summary(myfit)

birthweight_df %>% 
  add_predictions(myfit) %>% 
  add_residuals(myfit) %>% 
  ggplot(aes(x = pred, y = resid)) + geom_point()+
  labs(
    title = "Residuals against fitted values",
    x = "Fitted values",
    y = "Residuals"
  )
  

```

My model contains mother’s pre-pregnancy BMI, mother’s weight gain during pregnancy (in pounds) and gestational age in weeks as predictors. As the physcial fitness of mother is significant to the well-being of the babies. Also, the length of growth is also posibably important to the birth weight. We purpose a linear model in this case, the adjusted R-squared is 0.2158, therefore it is not a very good fit. The plot is  residuals against fitted values. Residuals spared around zero line, but it mainly gathers around 3000 - 3500, which means it is not a very good linear model. 

Here is the **code chunk** to compare my model to two others:

One using length at birth and gestational age as predictors (main effects only)
One using head circumference, length, sex, and all interactions (including the three-way interaction) between these

```{r message=FALSE, warning=FALSE}
cv_df = 
  cv_df %>% 
  mutate(my_mod    = map(train, ~lm(bwt ~ ppbmi + wtgain + gaweeks, data = .x)),
         given1_mod = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         given2_mod = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + babysex*bhead + bhead*blength*babysex, data = .x))) %>% 
  mutate(rmse_my    = map2_dbl(my_mod, test, ~rmse(model = .x, data = .y)),
         rmse_given1 = map2_dbl(given1_mod, test, ~rmse(model = .x, data = .y)),
         rmse_given2 = map2_dbl(given2_mod, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

The plot shows the RMSE of the three models. Smaller rmse indicates better model. Comparing with the three models, the second given model, which uses head circumference, length, sex, and all interactions (including the three-way interaction) between these, is the best fit. 



 

